{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\c_fre\\\\Learn.co\\\\Module_4_Project\\\\Image-Classification\\\\chest_xray\\\\train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ecc41a6291d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Create train and validation directories\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mtrain_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhome_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mval_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhome_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'val'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\c_fre\\\\Learn.co\\\\Module_4_Project\\\\Image-Classification\\\\chest_xray\\\\train'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Home directory\n",
    "home_path = r'C:\\Users\\c_fre\\Learn.co\\Module_4_Project\\Image-Classification\\chest_xray'\n",
    "\n",
    "# Create train and validation directories\n",
    "train_path = os.path.join(home_path,'train')\n",
    "os.mkdir(train_path)\n",
    "val_path = os.path.join(home_path,'val')\n",
    "os.mkdir(val_path)\n",
    "\n",
    "# Create sub-directories\n",
    "normal_train = os.path.join(home_path + r'/train','NORMAL')\n",
    "os.mkdir(normal_train)\n",
    "\n",
    "pneumonia_train = os.path.join(home_path + r'/train','PNEUMONIA')\n",
    "os.mkdir(pneumonia_train)\n",
    "\n",
    "normal_val = os.path.join(home_path + r'/val','NORMAL')\n",
    "os.mkdir(normal_val)\n",
    "\n",
    "pneumonia_val = os.path.join(home_path + r'/val','PNEUMONIA')\n",
    "os.mkdir(pneumonia_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-46966a1d7698>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhome_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34mr'/Users/c_fre/Learn.co/Module_4_Project/Image-Classification/chest_xray/train/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pneumonia_or_not'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pneumonia_or_not'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'str'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# requires target in string format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m train_generator_df = datagen.flow_from_dataframe(dataframe=df_train, \n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "# ImageDataGenerator flow_from_dataframe\n",
    "\n",
    "df_train = home_path + r'/Users/c_fre/Learn.co/Module_4_Project/Image-Classification/chest_xray/train/'\n",
    "df_train['pneumonia_or_not'] = df_train['pneumonia_or_not'].astype('str') # requires target in string format\n",
    "\n",
    "train_generator_df = datagen.flow_from_dataframe(dataframe=df_train, \n",
    "                                              directory=home_path+'/images/',\n",
    "                                              x_col=\"image_names\", \n",
    "                                              y_col=\"pneumonia_or_not\", \n",
    "                                              class_mode=\"binary\", \n",
    "                                              target_size=(200, 200), \n",
    "                                              batch_size=1,\n",
    "                                              rescale=1.0/255,\n",
    "                                              seed=2020)\n",
    "# plotting images\n",
    "fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(15,15))\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "  # convert to unsigned integers for plotting\n",
    "  image = next(train_generator_df)[0].astype('uint8')\n",
    "\n",
    "  # changing size from (1, 200, 200, 3) to (200, 200, 3) for plotting the image\n",
    "  image = np.squeeze(image)\n",
    "\n",
    "  # plot raw pixel data\n",
    "  ax[i].imshow(image)\n",
    "  ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Of Contents\n",
    "<font size=3rem>\n",
    "    \n",
    "0 -**[ INTRO](#INTRODUCTION)<br>**\n",
    "1 -**[ OBTAIN](#OBTAIN)**<br>\n",
    "2 -**[ PREPROCESSING](#PREPROCESSING)**<br>\n",
    "4 -**[ MODEL](#MODEL)**<br>\n",
    "5 -**[ INTERPRET](#INTERPRET)**<br>\n",
    "6 -**[ CONCLUSIONS & RECCOMENDATIONS](#Conclusions-&-Recommendations)<br>**\n",
    "</font>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Student: Cody Freese\n",
    "- Pace: Self Paced\n",
    "- Jeff Herman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pneumonia Chest Xray Image Classification\n",
    "    - Objective\n",
    "        - First I need to decide on:\n",
    "            - Accuracy\n",
    "            - Precision\n",
    "            - Recall\n",
    "            - F1 Score\n",
    "        - Priority\n",
    "            - (1) Do not want to tell a sick person they are healthy\n",
    "            \n",
    "            - (2) Accurately identify pneumonia\n",
    "            - (3) Tell healthy person they are sick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Home Directory\n",
    "home_path = r'C:\\Users\\c_fre\\Learn.co\\Module_4_Project\\Image-Classification\\chest_xray'\n",
    "\n",
    "#Train Directory\n",
    "train_path = os.path.join(home_path,'train')\n",
    "\n",
    "#Validation Directory\n",
    "val_path = os.path.join(home_path,'val')\n",
    "\n",
    "#Test Directory\n",
    "test_path = os.path.join(home_path,'test')\n",
    "\n",
    "#Train Subdirectories\n",
    "normal_train_path = os.path.join(train_path,'NORMAL')\n",
    "\n",
    "pneumonia_train_path = os.path.join(train_path,'PNEUMONIA')\n",
    "\n",
    "#Validation Subdirectories\n",
    "normal_val_path = os.path.join(val_path,'NORMAL')\n",
    "\n",
    "pneumonia_val_path = os.path.join(val_path,'PNEUMONIA')\n",
    "\n",
    "#Test Subdirectories\n",
    "\n",
    "normal_test_path = os.path.join(test_path,'NORMAL')\n",
    "\n",
    "pneumonia_test_path = os.path.join(test_path,'PNEUMONIA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory Contents: ['test', 'train', 'val']\n",
      "train Contents: ['NORMAL', 'PNEUMONIA']\n",
      "val Contents: ['NORMAL', 'PNEUMONIA']\n",
      "test Contents: ['NORMAL', 'PNEUMONIA']\n"
     ]
    }
   ],
   "source": [
    "#Observe Contents\n",
    "print('Directory Contents:',os.listdir(home_path))\n",
    "print('train Contents:',os.listdir(train_path))\n",
    "print('val Contents:',os.listdir(val_path))\n",
    "print('test Contents:',os.listdir(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases in Training: 5216\n",
      "Number of Pneumonia cases in Training: 3875\n",
      "Number of Normal cases in Training: 1341\n"
     ]
    }
   ],
   "source": [
    "#Cases in Training Sets\n",
    "print(\"Number of cases in Training:\",len(os.listdir(normal_train_path)) +len(os.listdir(pneumonia_train_path)))\n",
    "\n",
    "print(\"Number of Pneumonia cases in Training:\",len(os.listdir(pneumonia_train_path)))\n",
    "\n",
    "print(\"Number of Normal cases in Training:\",len(os.listdir(normal_train_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases in Validation: 16\n",
      "Number of Pneumonia cases in Validation: 8\n",
      "Number of Normal cases in Validation: 8\n"
     ]
    }
   ],
   "source": [
    "# Cases in Validation Sets\n",
    "print(\"Number of cases in Validation:\",len(os.listdir(normal_val_path)) +len(os.listdir(pneumonia_val_path)))\n",
    "\n",
    "print(\"Number of Pneumonia cases in Validation:\",len(os.listdir(pneumonia_val_path)))\n",
    "\n",
    "print(\"Number of Normal cases in Validation:\",len(os.listdir(normal_val_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases in Test: 624\n",
      "Number of Pneumonia cases in Test: 390\n",
      "Number of Normal cases in Test: 234\n"
     ]
    }
   ],
   "source": [
    "#Cases in Test Sets\n",
    "print(\"Number of cases in Test:\",len(os.listdir(normal_test_path)) +len(os.listdir(pneumonia_test_path)))\n",
    "\n",
    "print(\"Number of Pneumonia cases in Test:\",len(os.listdir(pneumonia_test_path)))\n",
    "\n",
    "print(\"Number of Normal cases in Test:\",len(os.listdir(normal_test_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Normal cases: 1583\n",
      "Total number of Pneumonia cases: 4273\n"
     ]
    }
   ],
   "source": [
    "# #Total number of Normal Cases\n",
    "print(\"Total number of Normal cases:\",\n",
    "      len(os.listdir(normal_test_path))+\n",
    "      len(os.listdir(normal_train_path))+\n",
    "      len(os.listdir(normal_val_path)))\n",
    "\n",
    "#Total number of Pneumonia Cases\n",
    "print(\"Total number of Pneumonia cases:\",\n",
    "      len(os.listdir(pneumonia_test_path))+\n",
    "      len(os.listdir(pneumonia_train_path))+\n",
    "      len(os.listdir(pneumonia_val_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 files belonging to 2 classes.\n",
      "Found 16 files belonging to 2 classes.\n",
      "Found 624 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = keras.preprocessing.image_dataset_from_directory(train_path,\n",
    "                                                                labels='inferred',\n",
    "                                                                label_mode='binary',\n",
    "                                                                smart_resize=True)\n",
    "\n",
    "val_dataset = keras.preprocessing.image_dataset_from_directory(val_path,\n",
    "                                                               labels='inferred',\n",
    "                                                               label_mode='binary',\n",
    "                                                               smart_resize=True)\n",
    "\n",
    "test_dataset = keras.preprocessing.image_dataset_from_directory(test_path,\n",
    "                                                               labels='inferred',\n",
    "                                                               label_mode='binary',\n",
    "                                                               smart_resize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 256, 256, 3), (None, 1)), types: (tf.float32, tf.float32)>\n",
      "<BatchDataset shapes: ((None, 256, 256, 3), (None, 1)), types: (tf.float32, tf.float32)>\n",
      "<BatchDataset shapes: ((None, 256, 256, 3), (None, 1)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(val_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Test Image\n",
    "img_path = '../C:/Users/c_fre/Learn.co/Module_4_Project/Image-Classification/chest_xray/val/NORMAL/NORMAL2-IM-1440-0001.jpeg'\n",
    "\n",
    "image = cv2.imread(img_path)\n",
    "\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.2) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-1bq9o88m\\opencv\\modules\\imgproc\\src\\resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-24f3bdf5b7ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mrows\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.2) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-1bq9o88m\\opencv\\modules\\imgproc\\src\\resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(15, 10))\n",
    "columns = 4; rows = 5\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = cv2.imread(#THIS NEEDS FIXING###[i])\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Normal size:  {train_dataset.shape}')\n",
    "# print(f'Pneumonia size:  {img_p.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "img_size = 150\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All below attempted to fit from ImageDataGenerator. Find way to make above fit with below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-50a3e1b7bd78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# ImageDataGenerator allows the network to \"see\" more diversified,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# but still representative, data points during training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m train_datagen = ImageDataGenerator(rescale = 1./255, # transform pixeles from range 0-255 to range 0-1\n\u001b[0m\u001b[0;32m      4\u001b[0m                                    \u001b[0mzoom_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# randomly zoom image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                    vertical_flip = True) # randomly flip images\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "# ImageDataGenerator allows us to 'rotate' to analyze the image in more than 2D\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, # transform pixeles from range 0-255 to range 0-1\n",
    "                                   zoom_range = 0.3, # randomly zoom image \n",
    "                                   vertical_flip = True) # randomly flip images\n",
    "\n",
    "# load a mini batch of images directly from the source folder then convert them into a vector of attributes\n",
    "training_set = train_datagen.flow_from_directory(directory = home_path + '/'+'train',\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 target_size = (img_size, img_size),\n",
    "                                                 shuffle = True,\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(directory = home_path + '/'+'test',\n",
    "                                            batch_size = batch_size,\n",
    "                                            target_size = (img_size, img_size),\n",
    "                                            shuffle = True,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st conv\n",
    "model.add(Conv2D(filters = 16, kernel_size = (3, 3), input_shape = (img_size, img_size, 3), activation = 'relu', padding = 'same'))\n",
    "model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd conv\n",
    "model.add(SeparableConv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\n",
    "model.add(SeparableConv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd conv\n",
    "model.add(SeparableConv2D(filters = 64, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\n",
    "model.add(SeparableConv2D(filters = 64, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4th conv\n",
    "model.add(SeparableConv2D(filters = 128, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\n",
    "model.add(SeparableConv2D(filters = 128, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(rate = 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5th\n",
    "model.add(SeparableConv2D(filters = 256, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\n",
    "model.add(SeparableConv2D(filters = 256, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(rate = 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connected layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 512, activation = 'relu'))\n",
    "model.add(Dropout(rate = 0.7))\n",
    "model.add(Dense(units = 128, activation = 'relu'))\n",
    "model.add(Dropout(rate = 0.5))\n",
    "model.add(Dense(units = 64, activation = 'relu'))\n",
    "model.add(Dropout(rate = 0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output layer\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequntial Compile\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback\n",
    "checkpoint = ModelCheckpoint(filepath = 'Pneumonia.h5', save_best_only = True, save_weights_only = True)\n",
    "lr_reduce = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.3, patience = 2, verbose = 2, mode = 'max')\n",
    "early_stop = EarlyStopping(monitor = 'val_loss', min_delta = 0.1, patience = 1, mode = 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit data to cnn model\n",
    "cnn = model.fit_generator(training_set,\n",
    "                          epochs = epochs,\n",
    "                          steps_per_epoch = training_set.samples // batch_size,\n",
    "                          validation_data = test_set,\n",
    "                          validation_steps = test_set.samples // batch_size,\n",
    "                          callbacks = [checkpoint, lr_reduce])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./Pneumonia.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input Test\n",
    "rand_img = np.random.randint(0, len(os.listdir(drct_path +'/'+ 'val/PNEUMONIA/')))\n",
    "rand_img_path = drct_path + '/'+'val/PNEUMONIA/' + os.listdir(drct_path +'/'+ 'val/PNEUMONIA/')[rand_img]\n",
    "\n",
    "img = plt.imread(rand_img_path)\n",
    "img = cv2.resize(img, (img_size, img_size))\n",
    "img = np.dstack([img, img, img])\n",
    "img = img.astype('float32') / 255\n",
    "result = model.predict(np.expand_dims(image.img_to_array(img), axis = 0))  \n",
    "\n",
    "if result[0][0] >0.5:\n",
    "  prediction = 'Pnuemonia'\n",
    "else:\n",
    "  prediction = 'Normal'\n",
    "  \n",
    "print(f'Predicted : ' + prediction)\n",
    "print ('Actual : Pnuemonia')\n",
    "\n",
    "image = plt.imread(rand_img_path)\n",
    "plt.imshow(image)\n",
    "plt.title('Pneumonia')\n",
    "plt.imshow(image, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "tn, fp, fn, tp = mat.ravel()\n",
    "print('Test Metrics:')\n",
    "precision = tp / (tp + fp) * 100\n",
    "recall = tp / (tp + fn) * 100\n",
    "print('Accuracy: {}%'.format(acc))\n",
    "print('Precision: {}%'.format(precision))\n",
    "print('Recall: {}%'.format(recall))\n",
    "print('F1-score: {}'.format(2*precision*recall/(precision+recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train Metric:')\n",
    "print('Train accuracy: {}%'.format(np.round(cnn.history['accuracy'][-1]*100, 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
